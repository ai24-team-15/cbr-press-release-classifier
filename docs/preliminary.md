<!-- theme: default -->
<!-- paginate: true -->
<!-- lang: ru -->

<style scoped>
    tr, td {
        background: none !important;
        border: none !important;
        width: 40%;
    }
    
    table {
        display: table;
        width: 100%;
        font-size: 18pt;
    }
    
    .icon {
        display: flex;
        gap: 0.5rem;
        margin-top: 2rem;
        font-size: 0.75rem;
    }
</style>

# Команда 15

## Классификатор пресс-релизов ЦБ с предсказанием будущей ключевой ставки

**Куратор проекта**: Ковалева Александра

**Участники проекта**:

<table>
    <tr>
        <td>Жарковский Дмитрий</td>
        <td>Кузьмин Дмитрий</td>
    </tr>
    <tr>
        <td>Иванов Иван</td>
        <td>Хадиев Руслан</td>
    </tr>
    <tr>
        <td>Куимов Владислав</td>
        <td></td>
    </tr>
</table>

<p class="icon">
    <img src="https://github.githubassets.com/favicons/favicon.svg"/>
    <a href="https://github.com/ai24-team-15">https://github.com/ai24-team-15</a>
</p>

---

# Постановка задачи

ЦБ каждый раз после заседания по ключевой ставке на сайте публикует пресс-релизы, в которых рассказывается про состояние экономики, инфляцию, спрос на продукты, услуги и т.д. и объясняет причину изменения/не изменения ставки.

Задача состоит в том, чтобы по семантике текста понять, что будет происходить с ключевой ставкой после на следующем заседании: ЦБ ее поднимет, опустит или оставит неизменной. Необходимо создать классификатор, который сможет определить тексты на 3 класса: -1 (ставка опустится), 0 (останется неизменной), 1 (ставку повысят).

---

# Цели по проекту на год

- ✅ Парсинг пресс-релизов с сайта ЦБ.
- ✅ Парсинг дополнительных данных: уровень инфляции и курс доллара США.
- ✅ Очистка и предобработка данных.
- ✅ Исследовательский анализ собранных данных и визуализации.
- ✅ Построение бейзлайна на тесктовых данных.
- ✅ Улучшение бейзлайна (классический ML).
- ✅ Обучение и выбор моделей с учетом дополнительных данных об уровне инфляции и курсе доллара США.

---

# Цели по проекту на год

- ✅ Создание API-сервиса и веб-приложения для демонстрации работы классификатора.
- ✅ Создание Docker образов для всех компонентов проекта и запуск приложения через Docker Compose.
- ⬜ Подготовка дополнительных эмбеддингов текстовых наблюдений (Word2Vec, FastText и т.п.).
- ⬜ Проектирование и обучение нейросетевых моделей, используя полученные ранее эмбединги и табличные данные.
- ⬜ Дообучение языковых моделей (например, BERT) на наших данных.

---

<style scoped>
    section {
        font-size: 1.25rem
    }
</style>

# Описание данных

Собранный датасет имеет следующую структуру:

- `date` - дата опубликования пресс-релиза;
- `link` - ссылка на пресс-релиз;
- `title` - заголовок пресс-релиза;
- `release` - текст пресс-релиза;
- `days_between` - количество дней прошедших до следующего релиза;
- `rate` - ключевая ставка утвержденная во время следующего заседания;
- `inflation` - значение инфляции в месяц следующего заседания (годовая);
- `usd` - курс доллара на день следующего заседания;
- `usd_cur_change_relative` - изменение курса доллара в день следующего заседания относительно дня текущего;
- `target_categorial` - изменение ключевой ставки на следующем заседании (-1 - уменьшена, 0 - без изменений, 1 - увеличена);
- `target_absolute` - абсолютное изменение ключевой ставки на следующем заседании (в процентах);
- `target_relative` - относительное изменение ключевой ставки утвержденной на следующем к ключевой ставке утвержденной на текущем заседании.

---

# Особенности данных

- Полученный датасет небольшой, всего 96 наблюдений.
- Наблюдается дисбаланс по классам: 43,2% наблюдений соответствует решениям о сохранении текущего уровня ключевой ставки, 31,6% - о понижении и 25,3% - о повышении.

---

# EDA

---

# Выбор метрик качества

Метрикой качества для сравнения моделей была выбрана ROC AUC OvO, поскольку она является интегральной (не зависит от порога перевода вероятностей в классы), а также не чувствительна к дисбалансу классов (в нашем датасете наблюдается небольшой дисбаланс).

---

# Описание бейзлайн-моделей и полученных метрик

**Бейзлайн**: направление изменения ставки будем предсказывать таким, как в последнем решении.

Данная модель имеет качество **0.749583** по метрике ROC AUC OvO.

---

# Улучшение бейзлайна

TODO: Описать, какие модели попробовали

---

<style scoped>
    section {
        padding: 1rem !important;
    }
    
    table {
        display: table;
        width: 100%;
    }
    
    table * {
        font-size: 10pt;
    }
    
    .yellow {
        background-color: yellow;
    }
</style>

# Метрики качества моделей

TODO: Добавить гиперпарметры, убрать лишние метрики

<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>Модель</th>
      <th>Accuracy</th>
      <th>F-score</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>ROC AUC OvR</th>
      <th>ROC AUC OvO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Минимальный бейзлайн</th>
      <td>0.663158</td>
      <td>0.667893</td>
      <td>0.669919</td>
      <td>0.666111</td>
      <td>0.745010</td>
      <td>0.749583</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов) + LogReg с L1-регуляризацией</th>
      <td>0.621212</td>
      <td>0.627058</td>
      <td>0.642995</td>
      <td>0.619311</td>
      <td>0.766783</td>
      <td>0.770722</td>
    </tr>
    <tr>
      <th>BoW + LogReg с L1-, L2-регуляризацией</th>
      <td>0.742424</td>
      <td>0.742770</td>
      <td>0.748213</td>
      <td>0.739544</td>
      <td>0.871739</td>
      <td>0.873204</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов + заголовки) + LogReg</th>
      <td>0.742424</td>
      <td>0.742770</td>
      <td>0.748213</td>
      <td>0.739544</td>
      <td>0.869994</td>
      <td>0.871488</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов + числовые переменные) + LogReg</th>
      <td>0.696970</td>
      <td>0.695807</td>
      <td>0.699183</td>
      <td>0.694222</td>
      <td>0.861922</td>
      <td>0.863797</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов) + SVM</th>
      <td>0.681818</td>
      <td>0.687595</td>
      <td>0.709524</td>
      <td>0.678521</td>
      <td>0.835474</td>
      <td>0.837417</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов) + LogReg с L1-регуляризацией</th>
      <td>0.606061</td>
      <td>0.613057</td>
      <td>0.643850</td>
      <td>0.601767</td>
      <td>0.784182</td>
      <td>0.787614</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов c доп. фильтрацией) + LogReg</th>
      <td>0.757576</td>
      <td>0.761220</td>
      <td>0.769459</td>
      <td>0.756484</td>
      <td>0.901642</td>
      <td>0.903270</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов + заголовки) + LogReg</th>
      <td>0.712121</td>
      <td>0.717903</td>
      <td>0.737500</td>
      <td>0.709954</td>
      <td>0.878747</td>
      <td>0.881341</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов + числовые переменные) + LogReg</th>
      <td>0.681818</td>
      <td>0.688457</td>
      <td>0.731248</td>
      <td>0.677314</td>
      <td>0.835872</td>
      <td>0.837195</td>
    </tr>
    <tr class="yellow">
      <th>TF-IDF (тексты релизов) + SVM</th>
      <td>0.772727</td>
      <td>0.776923</td>
      <td>0.790584</td>
      <td>0.770372</td>
      <td>0.926754</td>
      <td>0.927695</td>
    </tr>
    <tr>
      <th>N-граммы плюс Naive Bayes</th>
      <td>0.636364</td>
      <td>0.629318</td>
      <td>0.628042</td>
      <td>0.642321</td>
      <td>0.772995</td>
      <td>0.777142</td>
    </tr>
    <tr>
      <th>Word2Vec + LogReg</th>
      <td>0.560606</td>
      <td>0.563787</td>
      <td>0.562041</td>
      <td>0.566807</td>
      <td>0.727310</td>
      <td>0.732520</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель) + LogReg</th>
      <td>0.590909</td>
      <td>0.603136</td>
      <td>0.628721</td>
      <td>0.590929</td>
      <td>0.760629</td>
      <td>0.765176</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель с фильтрацией) + LogReg</th>
      <td>0.500000</td>
      <td>0.513921</td>
      <td>0.525107</td>
      <td>0.506388</td>
      <td>0.693653</td>
      <td>0.697273</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель) + SVM</th>
      <td>0.560606</td>
      <td>0.569858</td>
      <td>0.569858</td>
      <td>0.569858</td>
      <td>0.743541</td>
      <td>0.749317</td>
    </tr>
    <tr>
      <th>GloVe + LogReg</th>
      <td>0.606061</td>
      <td>0.611108</td>
      <td>0.684127</td>
      <td>0.596904</td>
      <td>0.763597</td>
      <td>0.768338</td>
    </tr>
  </tbody>
</table>

---

# Сервис FastAPI

TODO: описать, что было сделано

---

# Приложение Streamlit

TODO: описать, что было сделано

---

# Инфраструктура

- Подготовлены Dockerfile для построения образов сервиса и веб-приложения.
- Подготовлена конфигурация Docker Compose для запуска приложения.
- Настроена система сбора логов ELK, не зависимая от основного приложения и также запускаемая с помощью Docker Compose.
- Приложение и система сбора логов развернута в Yandex Cloud с использованием следующих сервисов:
    - Object Storage - для хранения рабочих датасетов;
    - Container Registry - для хранения и управления Docker-образами;
    - Compute Cloud - для создания виртуальной машины, на которой запущены приложения.
    
Приложение доступно по адресу http://cbr-classifier.ddns.net/

---

<style scoped>
    section {
        padding: 1rem !important;
    }
    
    img {
        width: 80%;
        height: auto;
    }
    
    p:has(> img) {
        text-align: center;
    }
</style>

#### Демонстрация работы сервиса

![screencast](app_screencast.gif)

---

<style scoped>
    section {
        padding: 1rem !important;
    }
    
    img {
        width: 80%;
        height: auto;
    }
    
    p:has(> img) {
        text-align: center;
    }
</style>

#### Демонстрация системы сбора логов

![screencast](logs_screencast.gif)

---

# Распределение работы в команде

---

# Цели по проекту на второе полугодие

- Подготовка дополнительных эмбеддингов текстовых наблюдений (Word2Vec, FastText и т.п.).
- Проектирование и обучение нейросетевых моделей, используя полученные ранее эмбединги и табличные данные.
- Дообучение языковых моделей (например, BERT) на наших данных.

#### Дополнительно:

- Ансамблирование моделей.
- Предсказание, на сколько процентных пунктов изменится ставка.
- Аугментация данных.
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Улучшенная версия Sentence Transformer с различными стратегиями агрегации"
      ],
      "metadata": {
        "id": "zemFEmcDS5OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXkPzaIc8H5k",
        "outputId": "4630bc87-3e5b-4970-d74c-4e354e09c35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import calc_metrics"
      ],
      "metadata": {
        "id": "3FsHA7GU8aul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import optuna\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#X = pd.read_csv(\"x.csv\", index_col=\"date\")\n",
        "#y = pd.read_csv(\"y.csv\", index_col=\"date\").iloc[:, 0]\n",
        "X = pd.read_csv(\"../data/x.csv\", index_col=\"date\")\n",
        "y = pd.read_csv(\"../data/y.csv\", index_col=\"date\").iloc[:, 0]\n",
        "\n",
        "class ImprovedSentenceTransformer:\n",
        "\n",
        "    def __init__(self, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        #Стандартный mean pooling\n",
        "        token_embeddings = model_output[0]\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    def max_pooling(self, model_output, attention_mask):\n",
        "        #Max pooling для выделения наиболее важных признаков\n",
        "        token_embeddings = model_output[0]\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        token_embeddings = token_embeddings * input_mask_expanded\n",
        "        return torch.max(token_embeddings, dim=1)[0]\n",
        "\n",
        "    def weighted_pooling(self, model_output, attention_mask):\n",
        "        #Взвешенный pooling с убывающими весами по позиции\n",
        "        token_embeddings = model_output[0]\n",
        "        seq_len = token_embeddings.size(1)\n",
        "\n",
        "        # Создаем веса: больший вес для начала текста\n",
        "        weights = torch.exp(-0.1 * torch.arange(seq_len, dtype=torch.float32))\n",
        "        weights = weights.to(self.device).unsqueeze(0).unsqueeze(-1)\n",
        "\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        weighted_embeddings = token_embeddings * input_mask_expanded * weights\n",
        "\n",
        "        return torch.sum(weighted_embeddings, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    def attention_pooling(self, model_output, attention_mask):\n",
        "        #Attention-based pooling\n",
        "        token_embeddings = model_output[0]\n",
        "        # Простой attention механизм\n",
        "        attention_weights = torch.tanh(token_embeddings).mean(dim=-1)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "        attention_weights = attention_weights.unsqueeze(-1)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        weighted_embeddings = token_embeddings * attention_weights * input_mask_expanded\n",
        "        return torch.sum(weighted_embeddings, 1)\n",
        "\n",
        "    def hierarchical_chunking(self, encoded_input, window_size=512, overlap=50, pad_token_id=1):\n",
        "        #Улучшенная стратегия разбиения с иерархической структурой\n",
        "        input_ids = encoded_input['input_ids']\n",
        "        n = input_ids.size(1)\n",
        "        # Если текст короткий, возвращаем как есть\n",
        "        if n <= window_size:\n",
        "            return encoded_input\n",
        "        step = window_size - overlap\n",
        "        num_chunks = (n + step - 1) // step\n",
        "        chunks = torch.full((num_chunks, window_size), pad_token_id, dtype=torch.long)\n",
        "        token_type_ids = torch.full((num_chunks, window_size), 0, dtype=torch.long)\n",
        "        attention_mask = torch.full((num_chunks, window_size), 0, dtype=torch.long)\n",
        "\n",
        "        chunk_positions = []\n",
        "        for i in range(num_chunks):\n",
        "            start = i * step\n",
        "            end = start + window_size\n",
        "            chunk_data = input_ids[:, start:end]\n",
        "            chunk_length = chunk_data.size(1)\n",
        "\n",
        "            chunks[i, :chunk_length] = chunk_data\n",
        "            attention_mask[i, :chunk_length] = 1\n",
        "\n",
        "            chunk_positions.append(i / max(1, num_chunks - 1))\n",
        "\n",
        "        return {\n",
        "            'input_ids': chunks,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'chunk_positions': torch.tensor(chunk_positions, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "    def smart_chunk_aggregation(self, chunk_embeddings, chunk_positions, strategy='weighted_importance'):\n",
        "        #Умная агрегация чанков с учетом их важности. Всегда возвращает тензор одинакового размера\n",
        "        base_dim = chunk_embeddings.size(-1)\n",
        "        if strategy == 'mean':\n",
        "            return chunk_embeddings.mean(0)\n",
        "        elif strategy == 'max':\n",
        "            return torch.max(chunk_embeddings, dim=0)[0]\n",
        "        elif strategy == 'weighted_position':\n",
        "            # Больший вес для начальных чанков\n",
        "            weights = torch.exp(-2 * chunk_positions).to(self.device)\n",
        "            weights = weights / weights.sum()\n",
        "            return torch.sum(chunk_embeddings * weights.unsqueeze(-1), dim=0)\n",
        "\n",
        "        elif strategy == 'attention_weighted':\n",
        "            # Attention-based веса для чанков\n",
        "            chunk_importance = torch.norm(chunk_embeddings, dim=1)\n",
        "            weights = F.softmax(chunk_importance, dim=0)\n",
        "            return torch.sum(chunk_embeddings * weights.unsqueeze(-1), dim=0)\n",
        "\n",
        "        elif strategy == 'concatenate_top_k':\n",
        "            # Берем top-k наиболее важных чанков, но возвращаем базовую размерность\n",
        "            k = min(3, len(chunk_embeddings))\n",
        "            chunk_importance = torch.norm(chunk_embeddings, dim=1)\n",
        "            top_k_indices = torch.topk(chunk_importance, k)[1]\n",
        "            selected_chunks = chunk_embeddings[top_k_indices]\n",
        "            return selected_chunks.mean(0)\n",
        "\n",
        "        else:# Комбинированная стратегия - возвращаем только взвешенное среднее\n",
        "            weights = torch.exp(-chunk_positions).to(self.device)\n",
        "            weights = weights / weights.sum()\n",
        "            return torch.sum(chunk_embeddings * weights.unsqueeze(-1), dim=0)\n",
        "\n",
        "    def extract_embeddings(self, texts, pooling_strategy='mean', chunk_aggregation='weighted_position'):\n",
        "        #Извлечение эмбеддингов с различными стратегиями\n",
        "        embeddings = []\n",
        "        expected_dim = None\n",
        "        for text in tqdm(texts, desc=\"Extracting embeddings\"):\n",
        "            enc_input = self.tokenizer(text, truncation=False, return_tensors='pt')\n",
        "            for key in enc_input:\n",
        "                enc_input[key] = enc_input[key].to(self.device)\n",
        "            if enc_input['input_ids'].size(1) > 512:\n",
        "                chunked_input = self.hierarchical_chunking(enc_input)\n",
        "                chunk_embeddings = []\n",
        "                with torch.no_grad():\n",
        "                    for i in range(chunked_input['input_ids'].size(0)):\n",
        "                        chunk_data = {\n",
        "                            'input_ids': chunked_input['input_ids'][i:i+1],\n",
        "                            'attention_mask': chunked_input['attention_mask'][i:i+1],\n",
        "                            'token_type_ids': chunked_input['token_type_ids'][i:i+1]\n",
        "                        }\n",
        "\n",
        "                        output = self.model(**chunk_data)\n",
        "\n",
        "                        if pooling_strategy == 'mean':\n",
        "                            embedding = self.mean_pooling(output, chunk_data['attention_mask'])\n",
        "                        elif pooling_strategy == 'max':\n",
        "                            embedding = self.max_pooling(output, chunk_data['attention_mask'])\n",
        "                        elif pooling_strategy == 'weighted':\n",
        "                            embedding = self.weighted_pooling(output, chunk_data['attention_mask'])\n",
        "                        elif pooling_strategy == 'attention':\n",
        "                            embedding = self.attention_pooling(output, chunk_data['attention_mask'])\n",
        "                        else:\n",
        "                            embedding = self.mean_pooling(output, chunk_data['attention_mask'])\n",
        "                        chunk_embeddings.append(embedding.squeeze(0))\n",
        "                chunk_embeddings = torch.stack(chunk_embeddings)\n",
        "\n",
        "                # Агрегируем чанки\n",
        "                final_embedding = self.smart_chunk_aggregation(\n",
        "                    chunk_embeddings,\n",
        "                    chunked_input['chunk_positions'],\n",
        "                    chunk_aggregation\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    output = self.model(**enc_input)\n",
        "                    if pooling_strategy == 'mean':\n",
        "                        final_embedding = self.mean_pooling(output, enc_input['attention_mask'])\n",
        "                    elif pooling_strategy == 'max':\n",
        "                        final_embedding = self.max_pooling(output, enc_input['attention_mask'])\n",
        "                    elif pooling_strategy == 'weighted':\n",
        "                        final_embedding = self.weighted_pooling(output, enc_input['attention_mask'])\n",
        "                    elif pooling_strategy == 'attention':\n",
        "                        final_embedding = self.attention_pooling(output, enc_input['attention_mask'])\n",
        "                    else:\n",
        "                        final_embedding = self.mean_pooling(output, enc_input['attention_mask'])\n",
        "                    final_embedding = final_embedding.squeeze(0)\n",
        "\n",
        "            if expected_dim is None:\n",
        "                expected_dim = final_embedding.size(0)\n",
        "            elif final_embedding.size(0) != expected_dim:\n",
        "                if final_embedding.size(0) > expected_dim:\n",
        "                    final_embedding = final_embedding[:expected_dim]\n",
        "                else:\n",
        "                    padding = torch.zeros(expected_dim - final_embedding.size(0))\n",
        "                    final_embedding = torch.cat([final_embedding, padding])\n",
        "            embeddings.append(final_embedding.cpu())\n",
        "        return torch.stack(embeddings)\n",
        "\n",
        "class AdvancedClassificationPipeline:\n",
        "    #Продвинутый pipeline для классификации с различными моделями и предобработкой\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_selector = None\n",
        "        self.pca = None\n",
        "        self.model = None\n",
        "\n",
        "    def create_ensemble_model(self, trial=None):\n",
        "        #Создание ensemble модели с подбором гиперпараметров\n",
        "        if trial is None:\n",
        "            return Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('model', GradientBoostingClassifier(\n",
        "                    n_estimators=200,\n",
        "                    learning_rate=0.1,\n",
        "                    max_depth=6,\n",
        "                    random_state=42\n",
        "                ))\n",
        "            ])\n",
        "\n",
        "        # Выбор модели\n",
        "        model_type = trial.suggest_categorical('model_type', ['rf', 'gb', 'svm', 'lr'])\n",
        "        steps = []\n",
        "        # Нормализация\n",
        "        if trial.suggest_categorical('use_scaling', [True, False]):\n",
        "            steps.append(('scaler', StandardScaler()))\n",
        "        # Отбор признаков\n",
        "        use_feature_selection = trial.suggest_categorical('use_feature_selection', [True, False])\n",
        "        if use_feature_selection:\n",
        "            k_features = trial.suggest_int('k_features', 50, 300)\n",
        "            steps.append(('feature_selector', SelectKBest(f_classif, k=k_features)))\n",
        "        # PCA\n",
        "        use_pca = trial.suggest_categorical('use_pca', [True, False])\n",
        "        if use_pca:\n",
        "            n_components = trial.suggest_int('n_components', 20, 100)\n",
        "            steps.append(('pca', PCA(n_components=n_components)))\n",
        "        # Модель\n",
        "        if model_type == 'rf':\n",
        "            model = RandomForestClassifier(\n",
        "                n_estimators=trial.suggest_int('n_estimators', 100, 500),\n",
        "                max_depth=trial.suggest_int('max_depth', 3, 20),\n",
        "                min_samples_split=trial.suggest_int('min_samples_split', 2, 20),\n",
        "                min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "        elif model_type == 'gb':\n",
        "            model = GradientBoostingClassifier(\n",
        "                n_estimators=trial.suggest_int('gb_n_estimators', 100, 300),\n",
        "                learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                max_depth=trial.suggest_int('gb_max_depth', 3, 10),\n",
        "                random_state=42\n",
        "            )\n",
        "        elif model_type == 'svm':\n",
        "            model = SVC(\n",
        "                C=trial.suggest_float('svm_C', 0.1, 10),\n",
        "                gamma=trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
        "                kernel=trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly']),\n",
        "                probability=True,\n",
        "                random_state=42\n",
        "            )\n",
        "        else: # lr\n",
        "            model = LogisticRegression(\n",
        "                C=trial.suggest_float('lr_C', 0.01, 10),\n",
        "                penalty=trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet', None]),\n",
        "                solver='saga',\n",
        "                random_state=42,\n",
        "                max_iter=1000\n",
        "            )\n",
        "\n",
        "        steps.append(('model', model))\n",
        "        return Pipeline(steps)\n",
        "\n",
        "def enhanced_objective(trial, embeddings, y, calc_metrics_func):\n",
        "    #Улучшенная целевая функция для оптимизации\n",
        "    pooling_strategy = trial.suggest_categorical('pooling_strategy',\n",
        "                                                ['mean', 'max', 'weighted', 'attention'])\n",
        "    chunk_aggregation = trial.suggest_categorical('chunk_aggregation',\n",
        "                                                 ['mean', 'max', 'weighted_position',\n",
        "                                                  'attention_weighted', 'combined'])\n",
        "    st_model = ImprovedSentenceTransformer()\n",
        "    # Создаем pipeline\n",
        "    pipeline_creator = AdvancedClassificationPipeline()\n",
        "    pipeline = pipeline_creator.create_ensemble_model(trial)\n",
        "\n",
        "    # Оцениваем качество\n",
        "    try:\n",
        "        metric, _ = calc_metrics_func(\n",
        "            embeddings,\n",
        "            y,\n",
        "            pipeline,\n",
        "            name=\"temp\",\n",
        "            plot=False,\n",
        "            calc_jobs=-1,\n",
        "        )\n",
        "        return metric\n",
        "    except Exception as e:\n",
        "        print(f\"Error in trial: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def experiment_with_strategies(X, y, calc_metrics_func):\n",
        "    #Эксперимент с различными стратегиями\n",
        "    st_model = ImprovedSentenceTransformer()\n",
        "    results = {}\n",
        "    strategies = [\n",
        "        ('mean', 'mean'),\n",
        "        ('mean', 'weighted_position'),\n",
        "        ('weighted', 'weighted_position'),\n",
        "        ('attention', 'attention_weighted'),\n",
        "        ('mean', 'combined'),\n",
        "        ('weighted', 'combined')\n",
        "    ]\n",
        "\n",
        "    for pooling_strategy, chunk_aggregation in strategies:\n",
        "        print(f\"Testing: pooling={pooling_strategy}, aggregation={chunk_aggregation}\")\n",
        "        embeddings = st_model.extract_embeddings(\n",
        "            X.release.tolist(),\n",
        "            pooling_strategy=pooling_strategy,\n",
        "            chunk_aggregation=chunk_aggregation\n",
        "        )\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('model', GradientBoostingClassifier(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=6,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "        # Оцениваем качество\n",
        "        metric, _ = calc_metrics_func(\n",
        "            embeddings,\n",
        "            y,\n",
        "            pipeline,\n",
        "            name=f\"ST_{pooling_strategy}_{chunk_aggregation}\",\n",
        "            plot=False,\n",
        "            calc_jobs=-1,\n",
        "        )\n",
        "\n",
        "        results[f\"{pooling_strategy}_{chunk_aggregation}\"] = metric\n",
        "        print(f\"F1 Score: {metric:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "    return results\n",
        "\n",
        "def run_simple_improved_transformer(X, y, calc_metrics_func):\n",
        "    print(\"=== Простая улучшенная модель Sentence Transformer ===\")\n",
        "    st_model = ImprovedSentenceTransformer()\n",
        "    safe_strategies = [\n",
        "        ('mean', 'mean'),\n",
        "        ('mean', 'weighted_position'),\n",
        "        ('weighted', 'weighted_position'),\n",
        "        ('attention', 'attention_weighted')\n",
        "    ]\n",
        "    best_score = 0\n",
        "    best_embeddings = None\n",
        "    best_strategy_name = \"\"\n",
        "    for pooling_strategy, chunk_aggregation in safe_strategies:\n",
        "        try:\n",
        "            print(f\"Тестирование: pooling={pooling_strategy}, aggregation={chunk_aggregation}\")\n",
        "\n",
        "            # Извлекаем эмбеддинги\n",
        "            embeddings = st_model.extract_embeddings(\n",
        "                X.release.tolist(),\n",
        "                pooling_strategy=pooling_strategy,\n",
        "                chunk_aggregation=chunk_aggregation\n",
        "            )\n",
        "            print(f\"Размер эмбеддингов: {embeddings.shape}\")\n",
        "            pipeline = Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('model', GradientBoostingClassifier(\n",
        "                    n_estimators=100,\n",
        "                    learning_rate=0.1,\n",
        "                    max_depth=6,\n",
        "                    random_state=42\n",
        "                ))\n",
        "            ])\n",
        "            metric_result, _ = calc_metrics_func(\n",
        "                embeddings,\n",
        "                y,\n",
        "                pipeline,\n",
        "                name=f\"ST_{pooling_strategy}_{chunk_aggregation}\",\n",
        "                plot=False,\n",
        "                calc_jobs=-1,\n",
        "            )\n",
        "\n",
        "            if isinstance(metric_result, pd.DataFrame):\n",
        "                metric = metric_result['f1'].iloc[0]\n",
        "            else:\n",
        "                metric = float(metric_result)\n",
        "\n",
        "            print(f\"F1 Score: {metric:.4f}\")\n",
        "\n",
        "            if metric > best_score:\n",
        "                best_score = metric\n",
        "                best_embeddings = embeddings\n",
        "                best_strategy_name = f\"{pooling_strategy}_{chunk_aggregation}\"\n",
        "\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка в стратегии {pooling_strategy}_{chunk_aggregation}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Лучшая стратегия: {best_strategy_name} с F1={best_score:.4f}\")\n",
        "\n",
        "    # Финальная оценка с лучшими эмбеддингами\n",
        "    if best_embeddings is not None:\n",
        "        print(\"Финальная оценка с лучшими эмбеддингами...\")\n",
        "\n",
        "        final_pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('feature_selection', SelectKBest(f_classif, k=min(200, best_embeddings.shape[1]))),\n",
        "            ('model', GradientBoostingClassifier(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=8,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        final_metric_result, _ = calc_metrics_func(\n",
        "            best_embeddings,\n",
        "            y,\n",
        "            final_pipeline,\n",
        "            name=\"Best Improved Sentence Transformer\",\n",
        "            plot=True,\n",
        "            calc_jobs=-1,\n",
        "        )\n",
        "\n",
        "        # Извлекаем числовое значение финальной метрики\n",
        "        if isinstance(final_metric_result, pd.DataFrame):\n",
        "            final_metric = final_metric_result['f1'].iloc[0]\n",
        "        else:\n",
        "            final_metric = float(final_metric_result)\n",
        "\n",
        "        return final_metric, best_strategy_name\n",
        "    else:\n",
        "        print(\"Не удалось найти работающую стратегию\")\n",
        "        return 0.0, \"none\"\n",
        "\n",
        "# Основная функция для запуска улучшенной модели\n",
        "def run_improved_sentence_transformer(X, y, calc_metrics_func, n_trials=100):\n",
        "    try:\n",
        "        final_metric, best_strategy = run_simple_improved_transformer(X, y, calc_metrics_func)\n",
        "        return final_metric, best_strategy\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка в простой версии: {e}\")\n",
        "        print(\"Переход к базовой версии...\")\n",
        "        st_model = ImprovedSentenceTransformer()\n",
        "        embeddings = st_model.extract_embeddings(\n",
        "            X.release.tolist(),\n",
        "            pooling_strategy='mean',\n",
        "            chunk_aggregation='mean'\n",
        "        )\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('model', RandomForestClassifier(\n",
        "                n_estimators=200,\n",
        "                max_depth=10,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        metric_result, _ = calc_metrics_func(\n",
        "            embeddings,\n",
        "            y,\n",
        "            pipeline,\n",
        "            name=\"Fallback Sentence Transformer\",\n",
        "            plot=True,\n",
        "            calc_jobs=-1,\n",
        "        )\n",
        "\n",
        "        if isinstance(metric_result, pd.DataFrame):\n",
        "            metric = metric_result['f1'].iloc[0]\n",
        "        else:\n",
        "            metric = float(metric_result)\n",
        "\n",
        "        return metric, \"fallback\"\n",
        "\n",
        "def run_safe_sentence_transformer(X, y, calc_metrics_func):\n",
        "    try:\n",
        "        from transformers import AutoTokenizer, AutoModel\n",
        "        import torch\n",
        "\n",
        "        print(\"Безопасная версия Sentence Transformer \")\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "        model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "\n",
        "        def mean_pooling(model_output, attention_mask):\n",
        "            token_embeddings = model_output[0]\n",
        "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "            return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "        embeddings = []\n",
        "        for text in tqdm(X.release.tolist(), desc=\"Extracting embeddings\"):\n",
        "            encoded_input = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "            encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model_output = model(**encoded_input)\n",
        "                sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "                embeddings.append(sentence_embedding.cpu().numpy().flatten())\n",
        "\n",
        "        embeddings = np.array(embeddings)\n",
        "        print(f\"Размер эмбеддингов: {embeddings.shape}\")\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('model', GradientBoostingClassifier(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=8,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "\n",
        "        metric_result, _ = calc_metrics_func(\n",
        "            embeddings,\n",
        "            y,\n",
        "            pipeline,\n",
        "            name=\"Safe Sentence Transformer\",\n",
        "            plot=True,\n",
        "            calc_jobs=-1,\n",
        "        )\n",
        "\n",
        "        if isinstance(metric_result, pd.DataFrame):\n",
        "            metric = metric_result['f1'].iloc[0]\n",
        "        else:\n",
        "            metric = float(metric_result)\n",
        "\n",
        "        return metric, \"safe_version\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка в безопасной версии: {e}\")\n",
        "        return 0.0, \"error\"\n",
        "\n"
      ],
      "metadata": {
        "id": "XRR6BDmYGwaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    final_metric, best_strategy = run_improved_sentence_transformer(X, y, calc_metrics)\n",
        "    if isinstance(final_metric, (int, float)):\n",
        "        print(f\"Финальная метрика: {final_metric:.4f}\")\n",
        "    else:\n",
        "        print(f\"Финальная метрика: {final_metric}\")\n",
        "    print(f\"Лучшая стратегия: {best_strategy}\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ib1HMQCQIpQM",
        "outputId": "11e35d55-69f8-47ad-942b-d827542a8954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Простая улучшенная модель Sentence Transformer ===\n",
            "Тестирование: pooling=mean, aggregation=mean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings:   0%|          | 0/100 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Extracting embeddings: 100%|██████████| 100/100 [04:02<00:00,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер эмбеддингов: torch.Size([100, 384])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.6216\n",
            "--------------------------------------------------\n",
            "Тестирование: pooling=mean, aggregation=weighted_position\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings: 100%|██████████| 100/100 [04:02<00:00,  2.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер эмбеддингов: torch.Size([100, 384])\n",
            "F1 Score: 0.6926\n",
            "--------------------------------------------------\n",
            "Тестирование: pooling=weighted, aggregation=weighted_position\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings: 100%|██████████| 100/100 [04:03<00:00,  2.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер эмбеддингов: torch.Size([100, 384])\n",
            "F1 Score: 0.6650\n",
            "--------------------------------------------------\n",
            "Тестирование: pooling=attention, aggregation=attention_weighted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings: 100%|██████████| 100/100 [04:04<00:00,  2.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер эмбеддингов: torch.Size([100, 384])\n",
            "F1 Score: 0.6773\n",
            "--------------------------------------------------\n",
            "Лучшая стратегия: mean_weighted_position с F1=0.6926\n",
            "Финальная оценка с лучшими эмбеддингами...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.67      0.43      0.53        23\n",
            "         0.0       0.50      0.57      0.53        28\n",
            "         1.0       0.57      0.68      0.62        19\n",
            "\n",
            "    accuracy                           0.56        70\n",
            "   macro avg       0.58      0.56      0.56        70\n",
            "weighted avg       0.57      0.56      0.55        70\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Финальная метрика: 0.5596\n",
            "Лучшая стратегия: mean_weighted_position\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Вариант 2: Максимально безопасная версия\\ntry:\\n    safe_metric, safe_strategy = run_safe_sentence_transformer(X, y, calc_metrics)\\n    if isinstance(safe_metric, (int, float)):\\n        print(f\"Безопасная метрика: {safe_metric:.4f}\")\\n    else:\\n        print(f\"Безопасная метрика: {safe_metric}\")\\n    print(f\"Стратегия: {safe_strategy}\")\\nexcept Exception as e:\\n    print(f\"Ошибка в безопасной версии: {e}\")\\n\\n# Вариант 3: Пошаговый запуск для отладки\\ntry:\\n    st_model = ImprovedSentenceTransformer()\\n    embeddings = st_model.extract_embeddings(X.release.tolist()[:10])  # Тестируем на 10 примерах\\n    print(f\"Тест успешен, размер: {embeddings.shape}\")\\nexcept Exception as e:\\n    print(f\"Ошибка в извлечении эмбеддингов: {e}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Основные улучшения в best_sentence_transformer_chunk:\n",
        "1. Множественные стратегии pooling\n",
        "Базовая модель: только mean pooling\n",
        "\n",
        "лучшенная модель: 4 стратегии\n",
        "\n",
        "- Mean pooling (стандартный)\n",
        "- Max pooling (выделение наиболее важных признаков)\n",
        "- Weighted pooling (больший вес для начала текста)\n",
        "- Attention pooling (механизм внимания)\n",
        "\n",
        "\n",
        "2. Продвинутые методы агрегации чанков\n",
        "Базовая модель: простое среднее по чанкам\n",
        "Улучшенная модель: 5 стратегий агрегации\n",
        "\n",
        "- Mean aggregation\n",
        "- Max aggregation\n",
        "- Weighted position (больший вес начальным чанкам)\n",
        "- Attention weighted (веса на основе важности)\n",
        "- Top-k concatenation (отбор наиболее важных чанков)\n",
        "\n",
        "3. Иерархическое разбиение текста\n",
        "4. Автоматический подбор лучшей стратегии\n",
        "Улучшенная модель тестирует разные комбинации стратегий и выбирает лучшую:\n",
        "Результаты метрик:\n",
        "- F1 Score:\n",
        "\n",
        "-- sentence_transformer_chunk - 0.502\n",
        "\n",
        "-- best_sentence_transformer_chunk - 0.692\n",
        "- Accuracy:\n",
        "\n",
        "-- sentence_transformer_chunk - 0.514\n",
        "\n",
        "-- best_sentence_transformer_chunk - 0.560\n",
        "\n",
        "Лучшая стратегия: mean + weighted_position"
      ],
      "metadata": {
        "id": "ToM-sindd2oh"
      }
    }
  ]
}
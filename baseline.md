## Построение бейзлайна

Цель данной работы построение бейзлайна и его улучшение с помощью простейших моделей, для предсказания направления изменения ставки рефинансирования ЦБ. Это наша отправная точка для сравнения и улучшения.

### План работы

0. Общая предобработка данных.
1. Минимальный бейзлайн.
2. Статистические методы :
    - Мешок слов плюс линейная модель
    - TF-IDF плюс линейная модель
    - N-граммы плюс Naive Bayes
3. Создание эмбеддингов:
    - Word2Vec плюс линейная модель
    - GloVe плюс линейная модель
4. Выводы

### Ноутбуки с экспериментами

- [min_baseline.ipynb](ml/min_baseline.ipynb) - минимальный бейзлайн. Модель предсказывает изменение ставки таким, как в последнем решении.
- [dummy.ipynb](ml/dummy.ipynb) - простейшее предсказание на основе самого частотного класса (вне рейтинга).
- [bag_of_words.ipynb](ml/bag_of_words.ipynb) - Bag of Words плюс линейные модели (логистическая регрессия регрессия и SVM).
- [tf_idf.ipynb](ml/tf_idf.ipynb) - TF-IDF плюс линейные модели. Здесь была получена наилучшая модель.
- [n_grams_naive_bayes.ipynb](ml/n_grams_naive_bayes.ipynb) - N-граммы плюс наивный байесовский классификатор.
- [word2vec.ipynb](ml/word2vec.ipynb) - Word2Vec плюс линейная модель.
- [glove.ipynb](ml/glove.ipynb) - GloVe плюс линейная модель.
- [pipeline.ipynb](ml/pipeline.ipynb) - пайплайн обучения и применения лучшей модели (TF-IDF + SVM).

### Метрики исследованных моделей

<style>td:last-child { font-weight: bold; }</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>Модель</th>
      <th>Accuracy</th>
      <th>F-score</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>ROC AUC OvR</th>
      <th>ROC AUC OvO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Минимальный бейзлайн</th>
      <td>0.663158</td>
      <td>0.667893</td>
      <td>0.669919</td>
      <td>0.666111</td>
      <td>0.745010</td>
      <td>0.749583</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов) + LogReg с L1-регуляризацией</th>
      <td>0.621212</td>
      <td>0.627058</td>
      <td>0.642995</td>
      <td>0.619311</td>
      <td>0.766783</td>
      <td>0.770722</td>
    </tr>
    <tr>
      <th>BoW + LogReg с L1-, L2-регуляризацией</th>
      <td>0.742424</td>
      <td>0.742770</td>
      <td>0.748213</td>
      <td>0.739544</td>
      <td>0.871739</td>
      <td>0.873204</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов + заголовки) + LogReg</th>
      <td>0.742424</td>
      <td>0.742770</td>
      <td>0.748213</td>
      <td>0.739544</td>
      <td>0.869994</td>
      <td>0.871488</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов + числовые переменные) + LogReg</th>
      <td>0.696970</td>
      <td>0.695807</td>
      <td>0.699183</td>
      <td>0.694222</td>
      <td>0.861922</td>
      <td>0.863797</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов) + SVM</th>
      <td>0.681818</td>
      <td>0.687595</td>
      <td>0.709524</td>
      <td>0.678521</td>
      <td>0.835474</td>
      <td>0.837417</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов) + LogReg с L1-регуляризацией</th>
      <td>0.606061</td>
      <td>0.613057</td>
      <td>0.643850</td>
      <td>0.601767</td>
      <td>0.784182</td>
      <td>0.787614</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов c доп. фильтрацией) + LogReg</th>
      <td>0.757576</td>
      <td>0.761220</td>
      <td>0.769459</td>
      <td>0.756484</td>
      <td>0.901642</td>
      <td>0.903270</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов + заголовки) + LogReg</th>
      <td>0.712121</td>
      <td>0.717903</td>
      <td>0.737500</td>
      <td>0.709954</td>
      <td>0.878747</td>
      <td>0.881341</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов + числовые переменные) + LogReg</th>
      <td>0.681818</td>
      <td>0.688457</td>
      <td>0.731248</td>
      <td>0.677314</td>
      <td>0.835872</td>
      <td>0.837195</td>
    </tr>
    <tr style="background-color: yellow;">
      <th>TF-IDF (тексты релизов) + SVM</th>
      <td>0.772727</td>
      <td>0.776923</td>
      <td>0.790584</td>
      <td>0.770372</td>
      <td>0.926754</td>
      <td>0.927695</td>
    </tr>
    <tr>
      <th>N-граммы плюс Naive Bayes</th>
      <td>0.636364</td>
      <td>0.629318</td>
      <td>0.628042</td>
      <td>0.642321</td>
      <td>0.772995</td>
      <td>0.777142</td>
    </tr>
    <tr>
      <th>Word2Vec + LogReg</th>
      <td>0.560606</td>
      <td>0.563787</td>
      <td>0.562041</td>
      <td>0.566807</td>
      <td>0.727310</td>
      <td>0.732520</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель) + LogReg</th>
      <td>0.590909</td>
      <td>0.603136</td>
      <td>0.628721</td>
      <td>0.590929</td>
      <td>0.760629</td>
      <td>0.765176</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель с фильтрацией) + LogReg</th>
      <td>0.500000</td>
      <td>0.513921</td>
      <td>0.525107</td>
      <td>0.506388</td>
      <td>0.693653</td>
      <td>0.697273</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель) + SVM</th>
      <td>0.560606</td>
      <td>0.569858</td>
      <td>0.569858</td>
      <td>0.569858</td>
      <td>0.743541</td>
      <td>0.749317</td>
    </tr>
    <tr>
      <th>GloVe + LogReg</th>
      <td>0.606061</td>
      <td>0.611108</td>
      <td>0.684127</td>
      <td>0.596904</td>
      <td>0.763597</td>
      <td>0.768338</td>
    </tr>
  </tbody>
</table>

### Выводы

В качестве бейзлайна построена модель, которая возвращает в качестве прогноза предыдущее решение о ставке рефинансирования.

Метрикой качества для сравнения моделей была выбрана ROC AUC OvO, поскольку она является интегральной (не зависит от порога перевода вероятностей в классы), а также не чувствительна к дисбалансу классов (в нашем датасете наблюдается небольшой дисбаланс).

В ходе экспериментов было исследовано несколько улучшений базовой модели. Наилучший результат среди них показала модель с векторизацией TF-IDF текстов релизов плюc SVM. Добавление дополнительной информации (заголовков, числовых переменных) не улучшало модели.

Алгоритмы Word2Vec и GloVe показали качество хуже, поскольку они неплохо создают представления слов, но в сумме этих представлений плохо сохраняется смысл всего текста.

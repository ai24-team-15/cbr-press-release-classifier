## Построение бейзлайна

Цель данной работы построение бейзлайна и его улучшение с помощью простейших моделей, для предсказания направления изменения ставки рефинансирования ЦБ. Это наша отправная точка для сравнения и улучшения.

### План работы

0. Общая предобработка данных.
1. Минимальный бейзлайн.
2. Статистические методы :
    - Мешок слов плюс линейная модель
    - TF-IDF плюс линейная модель
    - N-граммы плюс Naive Bayes
3. Создание эмбеддингов:
    - Word2Vec плюс линейная модель
    - GloVe плюс линейная модель
4. Выводы

### Ноутбуки с экспериментами

- [min_baseline.ipynb](ml/linear_models/min_baseline.ipynb) - минимальный бейзлайн. Модель предсказывает изменение ставки таким, как в последнем решении.
- [dummy.ipynb](ml/linear_models/dummy.ipynb) - простейшее предсказание на основе самого частотного класса (вне рейтинга).
- [bag_of_words.ipynb](ml/linear_models/bag_of_words.ipynb) - Bag of Words плюс линейные модели (логистическая регрессия регрессия и SVM).
- [tf_idf.ipynb](ml/linear_models/tf_idf.ipynb) - TF-IDF плюс линейные модели. Здесь была получена наилучшая модель.
- [n_grams_naive_bayes.ipynb](ml/linear_models/n_grams_naive_bayes.ipynb) - N-граммы плюс наивный байесовский классификатор.
- [word2vec.ipynb](ml/linear_models/word2vec.ipynb) - Word2Vec плюс линейная модель.
- [glove.ipynb](ml/linear_models/glove.ipynb) - GloVe плюс линейная модель.
- [pipeline.ipynb](ml/linear_models/pipeline.ipynb) - пайплайн обучения и применения лучшей модели (TF-IDF + SVM).

### Метрики исследованных моделей

<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>Модель</th>
      <th>Accuracy</th>
      <th>F-score</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>ROC AUC OvR</th>
      <th>ROC AUC OvO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Минимальный бейзлайн</th>
      <td>0.659794</td>
      <td>0.664127</td>
      <td>0.664127</td>
      <td>0.664127</td>
      <td>0.742845</td>
      <td>0.748095</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов) + LogReg с L1-регуляризацией</th>
      <td>0.632353</td>
      <td>0.639291</td>
      <td>0.645750</td>
      <td>0.634718</td>
      <td>0.755293</td>
      <td>0.761178</td>
    </tr>
    <tr>
      <th>BoW + LogReg с L1-, L2-регуляризацией</th>
      <td>0.676471</td>
      <td>0.682804</td>
      <td>0.696465</td>
      <td>0.674852</td>
      <td>0.837479</td>
      <td>0.840521</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов + заголовки) + LogReg</th>
      <td>0.661765</td>
      <td>0.666369</td>
      <td>0.684816</td>
      <td>0.657308</td>
      <td>0.834681</td>
      <td>0.837807</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов + числовые переменные) + LogReg</th>
      <td>0.676471</td>
      <td>0.681421</td>
      <td>0.690476</td>
      <td>0.676524</td>
      <td>0.833032</td>
      <td>0.836091</td>
    </tr>
    <tr>
      <th>BoW (тексты релизов) + SVM</th>
      <td>0.632353</td>
      <td>0.635330</td>
      <td>0.639098</td>
      <td>0.633046</td>
      <td>0.773909</td>
      <td>0.777299</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов) + LogReg с L1-регуляризацией</th>
      <td>0.632353</td>
      <td>0.633909</td>
      <td>0.639423</td>
      <td>0.633339</td>
      <td>0.779854</td>
      <td>0.785322</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов c доп. фильтрацией) + LogReg</th>
      <td>0.764706</td>
      <td>0.769046</td>
      <td>0.770299</td>
      <td>0.770962</td>
      <td>0.906871</td>
      <td>0.909142</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов + заголовки) + LogReg</th>
      <td>0.735294</td>
      <td>0.740476</td>
      <td>0.754672</td>
      <td>0.732529</td>
      <td>0.895373</td>
      <td>0.898903</td>
    </tr>
    <tr>
      <th>TF-IDF (тексты релизов + числовые переменные) + LogReg</th>
      <td>0.691176</td>
      <td>0.694553</td>
      <td>0.713392</td>
      <td>0.686000</td>
      <td>0.833339</td>
      <td>0.835035</td>
    </tr>
    <tr style="background-color: yellow;">
      <th>TF-IDF (тексты релизов) + SVM</th>
      <td>0.794118</td>
      <td>0.803775</td>
      <td>0.810649</td>
      <td>0.799654</td>
      <td>0.923914</td>
      <td>0.926773</td>
    </tr>
    <tr>
      <th>N-граммы плюс Naive Bayes</th>
      <td>0.632353</td>
      <td>0.627996</td>
      <td>0.625522</td>
      <td>0.644458</td>
      <td>0.763456</td>
      <td>0.769950</td>
    </tr>
    <tr>
      <th>Word2Vec + LogReg</th>
      <td>0.573529</td>
      <td>0.575836</td>
      <td>0.572222</td>
      <td>0.580385</td>
      <td>0.740064</td>
      <td>0.745570</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель) + LogReg</th>
      <td>0.588235</td>
      <td>0.602646</td>
      <td>0.617677</td>
      <td>0.592912</td>
      <td>0.753236</td>
      <td>0.760268</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель с фильтрацией) + LogReg</th>
      <td>0.529412</td>
      <td>0.552778</td>
      <td>0.581806</td>
      <td>0.536613</td>
      <td>0.709700</td>
      <td>0.717831</td>
    </tr>
    <tr>
      <th>Word2Vec (предобученная модель) + SVM</th>
      <td>0.544118</td>
      <td>0.554137</td>
      <td>0.550000</td>
      <td>0.559174</td>
      <td>0.696206</td>
      <td>0.704512</td>
    </tr>
    <tr>
      <th>GloVe + LogReg</th>
      <td>0.647059</td>
      <td>0.653199</td>
      <td>0.661626</td>
      <td>0.647539</td>
      <td>0.763768</td>
      <td>0.770111</td>
    </tr>
  </tbody>
</table>

### Выводы

В качестве бейзлайна построена модель, которая возвращает в качестве прогноза предыдущее решение о ставке рефинансирования.

Метрикой качества для сравнения моделей была выбрана ROC AUC OvO, поскольку она является интегральной (не зависит от порога перевода вероятностей в классы), а также не чувствительна к дисбалансу классов (в нашем датасете наблюдается небольшой дисбаланс).

В ходе экспериментов было исследовано несколько улучшений базовой модели. Наилучший результат среди них показала модель с векторизацией TF-IDF текстов релизов плюc SVM. Добавление дополнительной информации (заголовков, числовых переменных) не улучшало модели.

Алгоритмы Word2Vec и GloVe показали качество хуже, поскольку они неплохо создают представления слов, но в сумме этих представлений плохо сохраняется смысл всего текста.

Так же алгоритмы Word2Vec, GloVe демонстрируют низкие показатели, что возможно связано с размером выборки, который недостаточен для успешного обучения или плохо учитывает корреляцию между признаками. 

